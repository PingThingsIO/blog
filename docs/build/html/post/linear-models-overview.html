
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Linear Modeling Process Overview &#8212; NI4AI Blog 0.1 documentation</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="shortcut icon" href="../_static/tree.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    
      
      <link rel="icon" sizes="16x16" href="../_static/_static/tree.png">
      
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/PingThings_logo_color.png" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    
    
    <li class="nav-item">
        <a class="nav-link nav-external" href="https://btrdb.readthedocs.io/en/latest/">API Docs<i class="fas fa-external-link-alt"></i></a>
    </li>
    
    <li class="nav-item">
        <a class="nav-link nav-external" href="https://btrdb.readthedocs.io/en/latest/">PingThings<i class="fas fa-external-link-alt"></i></a>
    </li>
    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/PingThingsIO/ni4ai-notebooks" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="https://www.pingthings.io/" rel="noopener" target="_blank" title="PingThings">
            <span><i class="fa"></i></span>
            <label class="sr-only">PingThings</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                

<nav id="bd-toc-nav">
    
</nav>
              </div>
              
              <div class="toc-item">
                
              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <section id="linear-modeling-process-overview">
<h1>Linear Modeling Process Overview<a class="headerlink" href="#linear-modeling-process-overview" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="http://sdb.cs.berkeley.edu/sdb/btrdb.php">BTrDB (the Berkeley Tree Database)</a> is the core of the PredictiveGrid™ and implements a time series database API that is extremely effective for distributed analytics including the training of general linear models. To efficiently distribute storage to accommodate a high rate of data ingest from multiple sensors, data is stored in independent streams. As a result, univariate forecasting models are very easy to construct since, unlike querying a database table, queries are directly to measurement streams. Multivariate modeling usually takes two forms: either the expansion of features from a single stream (usually via FFT) or via an in-memory join of multiple streams that are time-aligned by the database.</p>
<p>The API supports raw values queries but also queries at arbitrary levels of time granularity with constant time aggregation. Moreover, the database has native support for windowing and time alignment queries, minimizing the work needed for pre-model data wrangling. We have bindings in multiple languages including <a class="reference external" href="https://pingthingsio.github.io/BTrDB.jl/v5.6/">Julia</a> and <a class="reference external" href="https://btrdb.readthedocs.io/en/latest/">Python</a>. Queries in Python return data as NumPy arrays or pandas Series or DataFrames. These formats are well suited for immediate use by the SciPy stack including basic time series analysis with lag means, cumulative series, ARIMA, or other seasonality based forecasting methods. Linear models can be easily implemented with either <a class="reference external" href="https://www.statsmodels.org/stable/index.html">StatsModels</a> or <a class="reference external" href="https://scikit-learn.org/stable/">scikit-learn.</a> Generally, we’ve found that non-parametric models such as random forest or gradient boosting perform best with the random walk-like voltage and current measurements we typically work on. However, data returned from a query can be easily funneled into any pipeline that exposes the scikit-learn API including logistic or polynomial regressions, stochastic gradient descent, SVMs, etc.</p>
<p>To provide ease of use for these types of low-density, in-memory computations, the platform is deployed with a standard <a class="reference external" href="https://jupyterhub.readthedocs.io/en/stable/">JupyterHub</a> environment that is pre-configured with database connection details. Our JupyterHub is deployed using <a class="reference external" href="https://kubernetes.io/">Kubernetes</a>, so user pods can be variably sized to different compute and memory requirements and all user pods are isolated from other users. JupyterHub also allows us to provide a user interface to distributed computing environments such as <a class="reference external" href="https://rise.cs.berkeley.edu/projects/ray/">Ray</a> and <a class="reference external" href="https://www.tensorflow.org/">TensorFlow.</a></p>
<p>For distributed analytics, we tend to prefer Ray, TensorFlow, and <a class="reference external" href="https://escholarship.org/content/qt61w8z66w/qt61w8z66w.pdf">DISTIL</a>, but have support for other distributed analytics frameworks such as Spark. Ray is a project currently in development at the UC Berkeley RISE Lab as a successor to <a class="reference external" href="https://spark.apache.org/">Spark.</a> We parallelize data in two ways to Ray and Spark executor nodes. The first method is to use <a class="reference external" href="https://arrow.apache.org/">Apache Arrow</a> and <a class="reference external" href="https://modin.readthedocs.io/en/latest/">Modin</a> to distribute a DataFrame across executors a cluster, this method ensures that the user has complete control of the data parallelization but creates a bottleneck at the user notebook. The second way is to partition the query, typically by time range, so that each executor independently queries the database for its shard, allowing parallel data loading from the database. In Spark, this is handled with a custom RDD type and in Ray using a special query decorator.</p>
<p>We have also found that deep learning time series methods such as RNNs and LSTMS are also effective for linear models on the data we have used. We have implemented a BTrDB-specific Dataset that extends the TensorFlow 2.0 Dataset to allow ease of batching and graph parallelization. Currently, the Dataset also parallelizes data with a bottleneck at the notebook because generated code is required to extend the SQLDataset type. Because this type is experimental, we’ve opted for simpler, NumPy-based streaming with batch queries. However, because TensorFlow epochs are generally longer than data loading time, this loader hasn’t been a major blocker to our deep learning modeling efforts.</p>
<p>Finally, we’ve implemented a novel, platform-specific distributed computation system called DISTIL. DISTIL is used to apply idempotent computations on real-time data as its ingested and to historical data as fast as system resources will allow. DISTIL is able to take handle out-of-order and out-of-time data and acts similarly to micro-batch systems such as Spark Streaming. DISTIL is primarily used for large scale pre-computation of features that will be used to train linear models, or to apply a linear model in real-time for just-in-time forecasting.</p>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, PingThings.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.3.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>